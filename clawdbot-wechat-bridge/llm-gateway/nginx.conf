server {
    listen 8081;
    server_name _;

    # Health check
    location /health {
        return 200 '{"status":"ok","service":"llm-gateway"}';
        add_header Content-Type application/json;
    }

    # Proxy all /v1/* requests to Zhipu AI OpenAI-compatible endpoint
    location /v1/ {
        proxy_pass https://open.bigmodel.cn/api/paas/v4/;

        # Inject the real API key (replaced by envsubst at container start)
        proxy_set_header Authorization "Bearer ${ZHIPU_API_KEY}";
        proxy_set_header Host open.bigmodel.cn;
        proxy_set_header Content-Type $http_content_type;
        proxy_set_header Accept $http_accept;

        # Timeouts for LLM requests (can be slow)
        proxy_connect_timeout 30s;
        proxy_read_timeout 300s;
        proxy_send_timeout 30s;

        # Pass through request body
        proxy_pass_request_body on;
        proxy_buffering off;

        # Gateway identifier header
        add_header X-LLM-Gateway "clawdbot" always;
    }
}
